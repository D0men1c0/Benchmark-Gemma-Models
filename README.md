# Gemma Benchmarking Suite

## Overview
This project is designed to benchmark the performance of various language models (like Gemma, Llama, etc.) on different NLP tasks. The framework is modular and supports multiple models, tasks, and evaluation metrics.

## Structure
- `config/`: Contains configuration files for the benchmarking process.
- `models/`: Classes responsible for loading models and running benchmarks.
- `evaluation/`: Contains evaluation logic for processing results.
- `utils/`: Utility functions for file management and logging.
- `scripts/`: Main script to execute the benchmarks.
- `results/`: Directory for storing benchmark results.

## Installation
```bash
pip install -r requirements.txt
