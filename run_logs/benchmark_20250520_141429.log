2025-05-20 14:14:33,836 - __main__ - MainThread - INFO - run_benchmark.main:85 - Loading configuration from: src\config\advanced_custom_benchmark_config.yaml
2025-05-20 14:14:33,836 - __main__ - MainThread - INFO - run_benchmark.load_config:26 - Configuration loaded and validated successfully from src\config\advanced_custom_benchmark_config.yaml
2025-05-20 14:14:33,836 - __main__ - MainThread - INFO - run_benchmark.main:96 - Initializing benchmark runner
2025-05-20 14:14:33,864 - BenchmarkRunner - MainThread - INFO - benchmark_loader._determine_device:33 - CUDA available. Using GPU.
2025-05-20 14:14:33,865 - __main__ - MainThread - INFO - run_benchmark.main:99 - Starting benchmark execution
2025-05-20 14:14:33,866 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_all_datasets:45 - Pre-loading datasets...
2025-05-20 14:14:33,866 - CustomScriptDatasetLoader.sample_themes_for_elaboration_en - MainThread - INFO - concrete_dataset_loader.__init__:396 - Initialized CustomScriptDatasetLoader for 'sample_themes_for_elaboration_en': script='src\benchmark\custom_loader_scripts\my_dataset_functions.py', function='load_simple_csv_data'
2025-05-20 14:14:33,866 - CustomScriptDatasetLoader.sample_themes_for_elaboration_en - MainThread - INFO - concrete_dataset_loader.load:412 - Loading custom dataset 'sample_themes_for_elaboration_en' using script 'src\benchmark\custom_loader_scripts\my_dataset_functions.py' and function 'load_simple_csv_data'
2025-05-20 14:14:33,867 - custom_dataset_module_sample_themes_for_elaboration_en_load_simple_csv_data - MainThread - INFO - my_dataset_functions.load_simple_csv_data:25 - load_simple_csv_data called for split: 'train', file: 'src/benchmark/custom_loader_scripts/data/sample_train_dataset.csv'
2025-05-20 14:14:33,867 - custom_dataset_module_sample_themes_for_elaboration_en_load_simple_csv_data - MainThread - INFO - my_dataset_functions.load_simple_csv_data:26 - Additional script_args: {}
2025-05-20 14:14:33,872 - custom_dataset_module_sample_themes_for_elaboration_en_load_simple_csv_data - MainThread - INFO - my_dataset_functions.load_simple_csv_data:38 - Loaded data from src\benchmark\custom_loader_scripts\data\sample_train_dataset.csv. Features: {'id': Value(dtype='string', id=None), 'text_content': Value(dtype='string', id=None), 'category_label': Value(dtype='int64', id=None)}
2025-05-20 14:14:33,872 - CustomScriptDatasetLoader.sample_themes_for_elaboration_en - MainThread - INFO - concrete_dataset_loader.load:462 - Applying cutoff: selecting first 8 samples from custom map-style dataset 'sample_themes_for_elaboration_en'. Original size: 100.
2025-05-20 14:14:33,873 - CustomScriptDatasetLoader.sample_themes_for_elaboration_en - MainThread - INFO - concrete_dataset_loader.load:485 - Custom dataset 'sample_themes_for_elaboration_en' loaded and potentially normalized for task_type 'custom_script'.
2025-05-20 14:14:33,873 - benchmark.dataset.concrete_dataset_loader - MainThread - INFO - concrete_dataset_loader.load:101 - Loading dataset: gsm8k (config: main, split: test)
2025-05-20 14:14:42,889 - benchmark.dataset.concrete_dataset_loader - MainThread - INFO - concrete_dataset_loader.load:114 - Applying cutoff: taking first 10 samples from iterable dataset 'gsm8k'. Original size: unknown (iterable).
2025-05-20 14:14:42,889 - benchmark.dataset.concrete_dataset_loader - MainThread - WARNING - concrete_dataset_loader._apply_renaming:261 - Renaming fields via mapping for IterableDataset: gsm8k (no caching for map function)
2025-05-20 14:14:42,889 - benchmark.dataset.concrete_dataset_loader - MainThread - INFO - concrete_dataset_loader.load:101 - Loading dataset: cais/mmlu (config: anatomy, split: test)
2025-05-20 14:14:51,087 - benchmark.dataset.concrete_dataset_loader - MainThread - INFO - concrete_dataset_loader.load:114 - Applying cutoff: taking first 10 samples from iterable dataset 'cais/mmlu'. Original size: unknown (iterable).
2025-05-20 14:14:51,087 - benchmark.dataset.concrete_dataset_loader - MainThread - WARNING - concrete_dataset_loader._apply_renaming:261 - Renaming fields via mapping for IterableDataset: cais/mmlu (no caching for map function)
2025-05-20 14:14:51,089 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_all_datasets:70 - Dataset loading complete.
2025-05-20 14:14:51,089 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:82 - --- Loading Model: gemma-2b-hf (huggingface, Quant: 4bit) ---
2025-05-20 14:14:51,089 - benchmark.models.models_factory - MainThread - INFO - models_factory.get_model_loader:50 - Loading model using huggingface framework
2025-05-20 14:14:51,089 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:31 - Loading model: google/gemma-2b with quantization: 4bit using HuggingFaceModelLoader
2025-05-20 14:14:51,091 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:66 - Using 4-bit quantization with compute dtype: torch.bfloat16
2025-05-20 14:14:51,091 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:80 - Offloading is enabled. Setting device_map='auto'.
2025-05-20 14:14:57,256 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:123 - Model 'gemma-2b-hf' loaded. Effective device(s): cuda:0.
2025-05-20 14:14:57,256 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'CreativeThemeElaboration_EN' for model 'google/gemma-2b'...
2025-05-20 14:14:57,256 - CustomScriptTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:14:57,256 - CustomScriptTaskHandler_pytorch - MainThread - INFO - concrete_task_handlers.__init__:769 - CustomScriptTaskHandler initialized to use creative_elaboration_processor from src\benchmark\custom_loader_scripts\my_task_handler_functions.py
2025-05-20 14:14:57,256 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:14:57,256 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:14:57,262 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'CreativeThemeElaboration_EN'. Intermediate log interval: 2
2025-05-20 14:14:57,264 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:14:57,264 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['The team worked collaboratively to achieve their goals. Healthy eating and regular exercise are important for well-being.', 'The weather is sunny and warm today. The new movie received excellent reviews from critics.']
2025-05-20 14:14:57,264 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:14:57,265 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:15:06,753 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:15:06,753 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:15:06,753 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['Learning a new language can be challenging but rewarding. The team worked collaboratively to achieve their goals.', 'Healthy eating and regular exercise are important for well-being. This is a complex problem that requires a creative solution.']
2025-05-20 14:15:06,753 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:15:06,753 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:15:15,910 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:15:15,910 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'CreativeThemeElaboration_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002042A6A6F00>> - Intermediate Metrics: {rouge: {'rouge1_f': '0.3110', 'rougeL_f': '0.3110'}, average_elaboration_length: 50.1250, keyword_match_count: 1.0000, keyword_match_ratio: 0.1250}
2025-05-20 14:15:15,910 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'CreativeThemeElaboration_EN'. Processed 2 batches.
2025-05-20 14:15:15,910 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rouge1', 'rougeL'], 'stats': ['f']}): {'rouge1_f': 0.311047916993869, 'rougeL_f': 0.311047916993869}
2025-05-20 14:15:15,918 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_avg_pred_length_state', 'metric_update_function_name': 'update_avg_pred_length_state', 'metric_result_function_name': 'result_avg_pred_length', 'metric_script_args': {'result_key_name': 'average_elaboration_length'}}): {'average_elaboration_length': 50.125}
2025-05-20 14:15:15,918 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_keyword_match_state', 'metric_update_function_name': 'update_keyword_match_state', 'metric_result_function_name': 'result_keyword_match', 'metric_script_args': {'keywords_to_match': ['theme', 'develop', 'idea', 'explore', 'story']}}): {'keyword_match_count': 1.0, 'keyword_match_ratio': 0.125}
2025-05-20 14:15:15,919 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'CreativeThemeElaboration_EN' on model 'google/gemma-2b': {rouge: {rouge1_f: 0.3110, rougeL_f: 0.3110}, average_elaboration_length: 50.1250, keyword_match_count: 1.0000, keyword_match_ratio: 0.1250}
2025-05-20 14:15:15,919 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'CreativeThemeElaboration_EN' on model 'google/gemma-2b' evaluation completed. Metrics requested: ['rouge', 'custom_script', 'custom_script']
2025-05-20 14:15:15,919 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'GSM8K_EN' for model 'google/gemma-2b'...
2025-05-20 14:15:15,919 - MathReasoningGenerationTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:15:15,920 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'GSM8K_EN'. Intermediate log interval: 2
2025-05-20 14:16:18,829 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'GSM8K_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002042A6A69F0>> - Intermediate Metrics: {exact_match: 0.0000, rouge: {'rougeL_f': '0.2688'}}
2025-05-20 14:16:35,323 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'GSM8K_EN'. Processed 3 batches.
2025-05-20 14:16:35,325 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {}): 0.0
2025-05-20 14:16:35,339 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rougeL'], 'stats': ['f']}): {'rougeL_f': 0.24957896841402843}
2025-05-20 14:16:35,339 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'GSM8K_EN' on model 'google/gemma-2b': {exact_match: 0.0000, rouge: {rougeL_f: 0.2496}}
2025-05-20 14:16:35,339 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'GSM8K_EN' on model 'google/gemma-2b' evaluation completed. Metrics requested: ['exact_match', 'rouge']
2025-05-20 14:16:35,339 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'MMLU_Anatomy_EN' for model 'google/gemma-2b'...
2025-05-20 14:16:35,343 - MultipleChoiceQATaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:35,344 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'MMLU_Anatomy_EN'. Intermediate log interval: 2
2025-05-20 14:16:37,223 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'MMLU_Anatomy_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002042A6B0A40>> - Intermediate Metrics: {exact_match: 0.3750, accuracy: 0.3750}
2025-05-20 14:16:38,017 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'MMLU_Anatomy_EN'. Processed 3 batches.
2025-05-20 14:16:38,017 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {'normalize': True, 'ignore_case': True}): 0.4
2025-05-20 14:16:38,017 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {}): 0.4
2025-05-20 14:16:38,017 - Evaluator - MainThread - WARNING - evaluator.finalize_results:133 - Metric name collision in final results: 'accuracy' (options: {'weighted': False}) is overwriting an existing entry with the same name.
2025-05-20 14:16:38,017 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {'weighted': False}): 0.4
2025-05-20 14:16:38,017 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'MMLU_Anatomy_EN' on model 'google/gemma-2b': {exact_match: 0.4000, accuracy: 0.4000}
2025-05-20 14:16:38,017 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'MMLU_Anatomy_EN' on model 'google/gemma-2b' evaluation completed. Metrics requested: ['exact_match', 'accuracy', 'accuracy']
2025-05-20 14:16:38,017 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:136 - Cleaning up resources for model 'google/gemma-2b'...
2025-05-20 14:16:38,175 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:142 - Resources cleaned up for model 'google/gemma-2b'.
2025-05-20 14:16:38,175 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:444 - Saving intermediate results after processing model 'gemma-2b-hf'...
2025-05-20 14:16:38,175 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:16:38,175 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:16:38,175 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:16:38,175 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:16:38,175 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:82 - --- Loading Model: gpt2-hf-standard (huggingface, Quant: None) ---
2025-05-20 14:16:38,175 - benchmark.models.models_factory - MainThread - INFO - models_factory.get_model_loader:50 - Loading model using huggingface framework
2025-05-20 14:16:38,180 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:31 - Loading model: gpt2 with quantization: None using HuggingFaceModelLoader
2025-05-20 14:16:38,180 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:91 - No quantization, offloading, or explicit device_map. Model loads on default device(s).
2025-05-20 14:16:38,180 - HuggingFaceModelLoader - MainThread - INFO - concrete_models.load:99 - Passing torch_dtype=torch.float32 to from_pretrained.
2025-05-20 14:16:39,367 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:108 - Moving model 'gpt2-hf-standard' to device 'cuda'.
2025-05-20 14:16:39,466 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:123 - Model 'gpt2-hf-standard' loaded. Effective device(s): cuda:0.
2025-05-20 14:16:39,489 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'CreativeThemeElaboration_EN' for model 'gpt2'...
2025-05-20 14:16:39,489 - CustomScriptTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:39,489 - CustomScriptTaskHandler_pytorch - MainThread - WARNING - base_task_handler.__init__:66 - Tokenizer for 'gpt2' has no pad_token. Setting pad_token to eos_token ('<|endoftext|>').
2025-05-20 14:16:39,489 - CustomScriptTaskHandler_pytorch - MainThread - INFO - concrete_task_handlers.__init__:769 - CustomScriptTaskHandler initialized to use creative_elaboration_processor from src\benchmark\custom_loader_scripts\my_task_handler_functions.py
2025-05-20 14:16:39,489 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:39,493 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:39,493 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'CreativeThemeElaboration_EN'. Intermediate log interval: 2
2025-05-20 14:16:39,494 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:16:39,494 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['The team worked collaboratively to achieve their goals. Healthy eating and regular exercise are important for well-being.', 'The weather is sunny and warm today. The new movie received excellent reviews from critics.']
2025-05-20 14:16:39,494 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:16:39,494 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:16:40,026 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:16:40,027 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:16:40,027 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['Learning a new language can be challenging but rewarding. The team worked collaboratively to achieve their goals.', 'Healthy eating and regular exercise are important for well-being. This is a complex problem that requires a creative solution.']
2025-05-20 14:16:40,027 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:16:40,027 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:16:40,469 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:16:40,469 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'CreativeThemeElaboration_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002042A6FBD70>> - Intermediate Metrics: {rouge: {'rouge1_f': '0.2337', 'rougeL_f': '0.2296'}, average_elaboration_length: 47.6250, keyword_match_count: 5.0000, keyword_match_ratio: 0.6250}
2025-05-20 14:16:40,479 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'CreativeThemeElaboration_EN'. Processed 2 batches.
2025-05-20 14:16:40,480 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rouge1', 'rougeL'], 'stats': ['f']}): {'rouge1_f': 0.23369662544442096, 'rougeL_f': 0.22959826478868328}
2025-05-20 14:16:40,483 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_avg_pred_length_state', 'metric_update_function_name': 'update_avg_pred_length_state', 'metric_result_function_name': 'result_avg_pred_length', 'metric_script_args': {'result_key_name': 'average_elaboration_length'}}): {'average_elaboration_length': 47.625}
2025-05-20 14:16:40,483 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_keyword_match_state', 'metric_update_function_name': 'update_keyword_match_state', 'metric_result_function_name': 'result_keyword_match', 'metric_script_args': {'keywords_to_match': ['theme', 'develop', 'idea', 'explore', 'story']}}): {'keyword_match_count': 5.0, 'keyword_match_ratio': 0.625}
2025-05-20 14:16:40,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'CreativeThemeElaboration_EN' on model 'gpt2': {rouge: {rouge1_f: 0.2337, rougeL_f: 0.2296}, average_elaboration_length: 47.6250, keyword_match_count: 5.0000, keyword_match_ratio: 0.6250}
2025-05-20 14:16:40,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'CreativeThemeElaboration_EN' on model 'gpt2' evaluation completed. Metrics requested: ['rouge', 'custom_script', 'custom_script']
2025-05-20 14:16:40,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'GSM8K_EN' for model 'gpt2'...
2025-05-20 14:16:40,484 - MathReasoningGenerationTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:40,484 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'GSM8K_EN'. Intermediate log interval: 2
2025-05-20 14:16:44,577 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'GSM8K_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002042A6BCBC0>> - Intermediate Metrics: {exact_match: 0.0000, rouge: {'rougeL_f': '0.2221'}}
2025-05-20 14:16:46,090 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'GSM8K_EN'. Processed 3 batches.
2025-05-20 14:16:46,091 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {}): 0.0
2025-05-20 14:16:46,116 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rougeL'], 'stats': ['f']}): {'rougeL_f': 0.24197209053435423}
2025-05-20 14:16:46,116 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'GSM8K_EN' on model 'gpt2': {exact_match: 0.0000, rouge: {rougeL_f: 0.2420}}
2025-05-20 14:16:46,116 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'GSM8K_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'rouge']
2025-05-20 14:16:46,116 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'MMLU_Anatomy_EN' for model 'gpt2'...
2025-05-20 14:16:46,116 - MultipleChoiceQATaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:46,117 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'MMLU_Anatomy_EN'. Intermediate log interval: 2
2025-05-20 14:16:46,427 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'MMLU_Anatomy_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423D42150>> - Intermediate Metrics: {exact_match: 0.6250, accuracy: 0.6250}
2025-05-20 14:16:46,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'MMLU_Anatomy_EN'. Processed 3 batches.
2025-05-20 14:16:46,483 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {'normalize': True, 'ignore_case': True}): 0.6
2025-05-20 14:16:46,483 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {}): 0.6
2025-05-20 14:16:46,483 - Evaluator - MainThread - WARNING - evaluator.finalize_results:133 - Metric name collision in final results: 'accuracy' (options: {'weighted': False}) is overwriting an existing entry with the same name.
2025-05-20 14:16:46,483 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {'weighted': False}): 0.6
2025-05-20 14:16:46,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'MMLU_Anatomy_EN' on model 'gpt2': {exact_match: 0.6000, accuracy: 0.6000}
2025-05-20 14:16:46,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'MMLU_Anatomy_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'accuracy', 'accuracy']
2025-05-20 14:16:46,483 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:136 - Cleaning up resources for model 'gpt2'...
2025-05-20 14:16:46,644 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:142 - Resources cleaned up for model 'gpt2'.
2025-05-20 14:16:46,644 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:444 - Saving intermediate results after processing model 'gpt2-hf-standard'...
2025-05-20 14:16:46,644 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:16:46,644 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:16:46,649 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:16:46,649 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:16:46,649 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:82 - --- Loading Model: gpt2-pytorch-loader (pytorch, Quant: None) ---
2025-05-20 14:16:46,650 - benchmark.models.models_factory - MainThread - INFO - models_factory.get_model_loader:50 - Loading model using pytorch framework
2025-05-20 14:16:46,650 - PyTorchModelLoader.gpt2 - MainThread - INFO - concrete_models.load:143 - Loading model: gpt2 (Quant: None, Offload in config: None) using PyTorchModelLoader
2025-05-20 14:16:46,650 - PyTorchModelLoader.gpt2 - MainThread - INFO - concrete_models.load:199 - PyTorchLoader: No BNB quantization, no explicit offloading, no device_map in kwargs. Model loads on default device(s).
2025-05-20 14:16:46,650 - PyTorchModelLoader.gpt2 - MainThread - INFO - concrete_models.load:204 - PyTorchLoader: Not using BNB, passing torch_dtype=torch.float32 to from_pretrained.
2025-05-20 14:16:47,388 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:108 - Moving model 'gpt2-pytorch-loader' to device 'cuda'.
2025-05-20 14:16:47,477 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:123 - Model 'gpt2-pytorch-loader' loaded. Effective device(s): cuda:0.
2025-05-20 14:16:47,478 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'CreativeThemeElaboration_EN' for model 'gpt2'...
2025-05-20 14:16:47,478 - CustomScriptTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:47,478 - CustomScriptTaskHandler_pytorch - MainThread - WARNING - base_task_handler.__init__:66 - Tokenizer for 'gpt2' has no pad_token. Setting pad_token to eos_token ('<|endoftext|>').
2025-05-20 14:16:47,478 - CustomScriptTaskHandler_pytorch - MainThread - INFO - concrete_task_handlers.__init__:769 - CustomScriptTaskHandler initialized to use creative_elaboration_processor from src\benchmark\custom_loader_scripts\my_task_handler_functions.py
2025-05-20 14:16:47,483 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:47,484 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:47,484 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'CreativeThemeElaboration_EN'. Intermediate log interval: 2
2025-05-20 14:16:47,484 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:16:47,485 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['The team worked collaboratively to achieve their goals. Healthy eating and regular exercise are important for well-being.', 'The weather is sunny and warm today. The new movie received excellent reviews from critics.']
2025-05-20 14:16:47,485 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:16:47,485 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:16:48,077 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:16:48,083 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:16:48,083 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['Learning a new language can be challenging but rewarding. The team worked collaboratively to achieve their goals.', 'Healthy eating and regular exercise are important for well-being. This is a complex problem that requires a creative solution.']
2025-05-20 14:16:48,083 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:16:48,083 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:16:48,605 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:16:48,611 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'CreativeThemeElaboration_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423CAC830>> - Intermediate Metrics: {rouge: {'rouge1_f': '0.1626', 'rougeL_f': '0.1576'}, average_elaboration_length: 46.8750, keyword_match_count: 4.0000, keyword_match_ratio: 0.5000}
2025-05-20 14:16:48,611 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'CreativeThemeElaboration_EN'. Processed 2 batches.
2025-05-20 14:16:48,617 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rouge1', 'rougeL'], 'stats': ['f']}): {'rouge1_f': 0.1626161021940209, 'rougeL_f': 0.1576161021940209}
2025-05-20 14:16:48,617 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_avg_pred_length_state', 'metric_update_function_name': 'update_avg_pred_length_state', 'metric_result_function_name': 'result_avg_pred_length', 'metric_script_args': {'result_key_name': 'average_elaboration_length'}}): {'average_elaboration_length': 46.875}
2025-05-20 14:16:48,617 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_keyword_match_state', 'metric_update_function_name': 'update_keyword_match_state', 'metric_result_function_name': 'result_keyword_match', 'metric_script_args': {'keywords_to_match': ['theme', 'develop', 'idea', 'explore', 'story']}}): {'keyword_match_count': 4.0, 'keyword_match_ratio': 0.5}
2025-05-20 14:16:48,617 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'CreativeThemeElaboration_EN' on model 'gpt2': {rouge: {rouge1_f: 0.1626, rougeL_f: 0.1576}, average_elaboration_length: 46.8750, keyword_match_count: 4.0000, keyword_match_ratio: 0.5000}
2025-05-20 14:16:48,617 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'CreativeThemeElaboration_EN' on model 'gpt2' evaluation completed. Metrics requested: ['rouge', 'custom_script', 'custom_script']
2025-05-20 14:16:48,617 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'GSM8K_EN' for model 'gpt2'...
2025-05-20 14:16:48,617 - MathReasoningGenerationTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:48,618 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'GSM8K_EN'. Intermediate log interval: 2
2025-05-20 14:16:52,914 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'GSM8K_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423D42150>> - Intermediate Metrics: {exact_match: 0.0000, rouge: {'rougeL_f': '0.2221'}}
2025-05-20 14:16:54,358 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'GSM8K_EN'. Processed 3 batches.
2025-05-20 14:16:54,358 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {}): 0.0
2025-05-20 14:16:54,377 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rougeL'], 'stats': ['f']}): {'rougeL_f': 0.24197209053435423}
2025-05-20 14:16:54,377 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'GSM8K_EN' on model 'gpt2': {exact_match: 0.0000, rouge: {rougeL_f: 0.2420}}
2025-05-20 14:16:54,387 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'GSM8K_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'rouge']
2025-05-20 14:16:54,387 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'MMLU_Anatomy_EN' for model 'gpt2'...
2025-05-20 14:16:54,387 - MultipleChoiceQATaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:16:54,388 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'MMLU_Anatomy_EN'. Intermediate log interval: 2
2025-05-20 14:16:54,677 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'MMLU_Anatomy_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423D1B8F0>> - Intermediate Metrics: {exact_match: 0.6250, accuracy: 0.6250}
2025-05-20 14:16:54,732 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'MMLU_Anatomy_EN'. Processed 3 batches.
2025-05-20 14:16:54,732 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {'normalize': True, 'ignore_case': True}): 0.6
2025-05-20 14:16:54,732 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {}): 0.6
2025-05-20 14:16:54,732 - Evaluator - MainThread - WARNING - evaluator.finalize_results:133 - Metric name collision in final results: 'accuracy' (options: {'weighted': False}) is overwriting an existing entry with the same name.
2025-05-20 14:16:54,732 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {'weighted': False}): 0.6
2025-05-20 14:16:54,732 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'MMLU_Anatomy_EN' on model 'gpt2': {exact_match: 0.6000, accuracy: 0.6000}
2025-05-20 14:16:54,739 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'MMLU_Anatomy_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'accuracy', 'accuracy']
2025-05-20 14:16:54,739 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:136 - Cleaning up resources for model 'gpt2'...
2025-05-20 14:16:54,891 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:142 - Resources cleaned up for model 'gpt2'.
2025-05-20 14:16:54,891 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:444 - Saving intermediate results after processing model 'gpt2-pytorch-loader'...
2025-05-20 14:16:54,891 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:16:54,891 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:16:54,892 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:16:54,892 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:16:54,892 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:82 - --- Loading Model: gpt2-tensorflow-loader (tensorflow, Quant: None) ---
2025-05-20 14:16:54,892 - benchmark.models.models_factory - MainThread - INFO - models_factory.get_model_loader:50 - Loading model using tensorflow framework
2025-05-20 14:16:54,893 - TensorFlowModelLoader.gpt2 - MainThread - INFO - concrete_models.load:243 - Loading model: gpt2 with quantization: None using TensorFlowModelLoader
2025-05-20 14:16:54,893 - TensorFlowModelLoader.gpt2 - MainThread - INFO - concrete_models.load:270 - TensorFlowModelLoader: Device placement is handled by TensorFlow's default behavior or distribution strategies.
2025-05-20 14:16:58,587 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:123 - Model 'gpt2-tensorflow-loader' loaded. Effective device(s): cuda.
2025-05-20 14:16:58,593 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'CreativeThemeElaboration_EN' for model 'gpt2'...
2025-05-20 14:16:58,597 - CustomScriptTaskHandler_tensorflow - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'tensorflow' model.
2025-05-20 14:16:58,597 - CustomScriptTaskHandler_tensorflow - MainThread - WARNING - base_task_handler.__init__:66 - Tokenizer for 'gpt2' has no pad_token. Setting pad_token to eos_token ('<|endoftext|>').
2025-05-20 14:16:58,599 - CustomScriptTaskHandler_tensorflow - MainThread - INFO - concrete_task_handlers.__init__:769 - CustomScriptTaskHandler initialized to use creative_elaboration_processor from src\benchmark\custom_loader_scripts\my_task_handler_functions.py
2025-05-20 14:16:58,600 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:58,600 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:16:58,601 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'CreativeThemeElaboration_EN'. Intermediate log interval: 2
2025-05-20 14:16:58,601 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:16:58,602 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['The team worked collaboratively to achieve their goals. Healthy eating and regular exercise are important for well-being.', 'The weather is sunny and warm today. The new movie received excellent reviews from critics.']
2025-05-20 14:16:58,602 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:16:58,602 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:17:06,820 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:17:06,820 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:17:06,820 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['Learning a new language can be challenging but rewarding. The team worked collaboratively to achieve their goals.', 'Healthy eating and regular exercise are important for well-being. This is a complex problem that requires a creative solution.']
2025-05-20 14:17:06,820 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:17:06,820 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:17:14,734 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:17:14,734 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'CreativeThemeElaboration_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423D43710>> - Intermediate Metrics: {rouge: {'rouge1_f': '0.1770', 'rougeL_f': '0.1770'}, average_elaboration_length: 47.0000, keyword_match_count: 4.0000, keyword_match_ratio: 0.5000}
2025-05-20 14:17:14,734 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'CreativeThemeElaboration_EN'. Processed 2 batches.
2025-05-20 14:17:14,734 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rouge1', 'rougeL'], 'stats': ['f']}): {'rouge1_f': 0.1769682330106994, 'rougeL_f': 0.1769682330106994}
2025-05-20 14:17:14,734 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_avg_pred_length_state', 'metric_update_function_name': 'update_avg_pred_length_state', 'metric_result_function_name': 'result_avg_pred_length', 'metric_script_args': {'result_key_name': 'average_elaboration_length'}}): {'average_elaboration_length': 47.0}
2025-05-20 14:17:14,734 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_keyword_match_state', 'metric_update_function_name': 'update_keyword_match_state', 'metric_result_function_name': 'result_keyword_match', 'metric_script_args': {'keywords_to_match': ['theme', 'develop', 'idea', 'explore', 'story']}}): {'keyword_match_count': 4.0, 'keyword_match_ratio': 0.5}
2025-05-20 14:17:14,734 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'CreativeThemeElaboration_EN' on model 'gpt2': {rouge: {rouge1_f: 0.1770, rougeL_f: 0.1770}, average_elaboration_length: 47.0000, keyword_match_count: 4.0000, keyword_match_ratio: 0.5000}
2025-05-20 14:17:14,734 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'CreativeThemeElaboration_EN' on model 'gpt2' evaluation completed. Metrics requested: ['rouge', 'custom_script', 'custom_script']
2025-05-20 14:17:14,745 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'GSM8K_EN' for model 'gpt2'...
2025-05-20 14:17:14,745 - MathReasoningGenerationTaskHandler_tensorflow - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'tensorflow' model.
2025-05-20 14:17:14,746 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'GSM8K_EN'. Intermediate log interval: 2
2025-05-20 14:18:11,725 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'GSM8K_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020423C9D550>> - Intermediate Metrics: {exact_match: 0.0000, rouge: {'rougeL_f': '0.2750'}}
2025-05-20 14:18:37,430 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'GSM8K_EN'. Processed 3 batches.
2025-05-20 14:18:37,430 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {}): 0.0
2025-05-20 14:18:37,461 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rougeL'], 'stats': ['f']}): {'rougeL_f': 0.25506379497488996}
2025-05-20 14:18:37,461 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'GSM8K_EN' on model 'gpt2': {exact_match: 0.0000, rouge: {rougeL_f: 0.2551}}
2025-05-20 14:18:37,462 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'GSM8K_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'rouge']
2025-05-20 14:18:37,462 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'MMLU_Anatomy_EN' for model 'gpt2'...
2025-05-20 14:18:37,462 - MultipleChoiceQATaskHandler_tensorflow - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'tensorflow' model.
2025-05-20 14:18:37,463 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'MMLU_Anatomy_EN'. Intermediate log interval: 2
2025-05-20 14:18:39,314 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'MMLU_Anatomy_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x00000204331C1460>> - Intermediate Metrics: {exact_match: 0.6250, accuracy: 0.6250}
2025-05-20 14:18:40,086 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'MMLU_Anatomy_EN'. Processed 3 batches.
2025-05-20 14:18:40,086 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {'normalize': True, 'ignore_case': True}): 0.6
2025-05-20 14:18:40,086 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {}): 0.6
2025-05-20 14:18:40,086 - Evaluator - MainThread - WARNING - evaluator.finalize_results:133 - Metric name collision in final results: 'accuracy' (options: {'weighted': False}) is overwriting an existing entry with the same name.
2025-05-20 14:18:40,086 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {'weighted': False}): 0.6
2025-05-20 14:18:40,086 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'MMLU_Anatomy_EN' on model 'gpt2': {exact_match: 0.6000, accuracy: 0.6000}
2025-05-20 14:18:40,086 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'MMLU_Anatomy_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'accuracy', 'accuracy']
2025-05-20 14:18:40,086 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:136 - Cleaning up resources for model 'gpt2'...
2025-05-20 14:18:40,252 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:142 - Resources cleaned up for model 'gpt2'.
2025-05-20 14:18:40,252 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:444 - Saving intermediate results after processing model 'gpt2-tensorflow-loader'...
2025-05-20 14:18:40,252 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:18:40,252 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:18:40,252 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:18:40,252 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:18:40,252 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:82 - --- Loading Model: gpt2-custom-script-loader (custom_script, Quant: None) ---
2025-05-20 14:18:40,252 - benchmark.models.models_factory - MainThread - INFO - models_factory.get_model_loader:50 - Loading model using custom_script framework
2025-05-20 14:18:40,252 - CustomScriptModelLoader.gpt2 - MainThread - INFO - concrete_models.__init__:345 - Initialized CustomScriptModelLoader for 'gpt2': script='src\benchmark\custom_loader_scripts\my_model_functions.py', function='load_local_hf_model_example', framework='custom_script'
2025-05-20 14:18:40,252 - CustomScriptModelLoader.gpt2 - MainThread - INFO - concrete_models.load:359 - Loading custom model 'gpt2' using function 'load_local_hf_model_example' from script 'src\benchmark\custom_loader_scripts\my_model_functions.py'
2025-05-20 14:18:40,252 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:31 - Custom model loading function 'load_local_hf_model_example' called.
2025-05-20 14:18:40,252 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:32 -   Model Path: gpt2
2025-05-20 14:18:40,252 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:33 -   Tokenizer Path/Name: gpt2
2025-05-20 14:18:40,252 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:34 -   Quantization: None
2025-05-20 14:18:40,252 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:35 -   Torch Dtype: float32
2025-05-20 14:18:40,263 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:36 -   Device Map: auto
2025-05-20 14:18:40,263 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:37 -   Model Load Args: None
2025-05-20 14:18:40,263 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:38 -   Other Script Args: {}
2025-05-20 14:18:40,263 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:44 -   Interpreting 'gpt2' as a Hugging Face Hub model ID (or a path that will be resolved by HF).
2025-05-20 14:18:40,531 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:51 - Tokenizer loaded from: gpt2
2025-05-20 14:18:40,531 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:97 - No bitsandbytes quantization. device_map: auto, torch_dtype: torch.float32
2025-05-20 14:18:40,531 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:104 - Loading model from 'gpt2' with args: {'trust_remote_code': True, 'device_map': 'auto', 'torch_dtype': torch.float32}
2025-05-20 14:18:41,480 - custom_model_module.my_model_functions_load_local_hf_model_example - MainThread - INFO - my_model_functions.load_local_hf_model_example:109 - Model loaded successfully from: gpt2
2025-05-20 14:18:41,480 - CustomScriptModelLoader.gpt2 - MainThread - INFO - concrete_models.load:409 - Custom model 'gpt2' and tokenizer loaded successfully from script.
2025-05-20 14:18:41,480 - BenchmarkRunner - MainThread - INFO - benchmark_loader._load_model_and_tokenizer:123 - Model 'gpt2-custom-script-loader' loaded. Effective device(s): cuda:0.
2025-05-20 14:18:41,506 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'CreativeThemeElaboration_EN' for model 'gpt2'...
2025-05-20 14:18:41,506 - CustomScriptTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:18:41,507 - CustomScriptTaskHandler_pytorch - MainThread - WARNING - base_task_handler.__init__:66 - Tokenizer for 'gpt2' has no pad_token. Setting pad_token to eos_token ('<|endoftext|>').
2025-05-20 14:18:41,507 - CustomScriptTaskHandler_pytorch - MainThread - INFO - concrete_task_handlers.__init__:769 - CustomScriptTaskHandler initialized to use creative_elaboration_processor from src\benchmark\custom_loader_scripts\my_task_handler_functions.py
2025-05-20 14:18:41,509 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:18:41,510 - benchmark.evaluation.metrics.concrete_metrics - MainThread - INFO - concrete_metrics.set_options:1263 - CustomScriptMetric initialized with functions from src\benchmark\custom_loader_scripts\my_metrics_functions.py
2025-05-20 14:18:41,511 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'CreativeThemeElaboration_EN'. Intermediate log interval: 2
2025-05-20 14:18:41,511 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:18:41,511 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['The team worked collaboratively to achieve their goals. Healthy eating and regular exercise are important for well-being.', 'The weather is sunny and warm today. The new movie received excellent reviews from critics.']
2025-05-20 14:18:41,511 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:18:41,511 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:18:42,058 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:18:42,058 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:98 - Executing prepare_creative_elaboration_prompts. Batch keys: ['id', 'text_content', 'category_label']. Script_args: {}
2025-05-20 14:18:42,059 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:111 -   Cleaned input themes (first 2 if many): ['Learning a new language can be challenging but rewarding. The team worked collaboratively to achieve their goals.', 'Healthy eating and regular exercise are important for well-being. This is a complex problem that requires a creative solution.']
2025-05-20 14:18:42,059 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:115 -   Using prompt template for creative elaboration: "Expand on this idea with a creative paragraph:
Idea: {theme}

Creative Paragraph:"
2025-05-20 14:18:42,059 - custom_handler_module.creative_elaboration_processor - MainThread - INFO - my_task_handler_functions.creative_elaboration_processor:124 -   Prepared 4 prompts.
2025-05-20 14:18:42,498 - benchmark.postprocessing.concrete_postprocessors - MainThread - INFO - concrete_postprocessors._load_custom_function:314 - CustomScriptPostProcessor loaded clean_elaboration_output from src\benchmark\custom_loader_scripts\my_post_processor_functions.py
2025-05-20 14:18:42,498 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'CreativeThemeElaboration_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020432ADFE60>> - Intermediate Metrics: {rouge: {'rouge1_f': '0.1449', 'rougeL_f': '0.1449'}, average_elaboration_length: 47.8750, keyword_match_count: 6.0000, keyword_match_ratio: 0.7500}
2025-05-20 14:18:42,498 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'CreativeThemeElaboration_EN'. Processed 2 batches.
2025-05-20 14:18:42,505 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rouge1', 'rougeL'], 'stats': ['f']}): {'rouge1_f': 0.1449281747420927, 'rougeL_f': 0.1449281747420927}
2025-05-20 14:18:42,505 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_avg_pred_length_state', 'metric_update_function_name': 'update_avg_pred_length_state', 'metric_result_function_name': 'result_avg_pred_length', 'metric_script_args': {'result_key_name': 'average_elaboration_length'}}): {'average_elaboration_length': 47.875}
2025-05-20 14:18:42,505 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'custom_script' (options: {'metric_script_path': 'src/benchmark/custom_loader_scripts/my_metrics_functions.py', 'metric_init_function_name': 'init_keyword_match_state', 'metric_update_function_name': 'update_keyword_match_state', 'metric_result_function_name': 'result_keyword_match', 'metric_script_args': {'keywords_to_match': ['theme', 'develop', 'idea', 'explore', 'story']}}): {'keyword_match_count': 6.0, 'keyword_match_ratio': 0.75}
2025-05-20 14:18:42,505 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'CreativeThemeElaboration_EN' on model 'gpt2': {rouge: {rouge1_f: 0.1449, rougeL_f: 0.1449}, average_elaboration_length: 47.8750, keyword_match_count: 6.0000, keyword_match_ratio: 0.7500}
2025-05-20 14:18:42,507 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'CreativeThemeElaboration_EN' on model 'gpt2' evaluation completed. Metrics requested: ['rouge', 'custom_script', 'custom_script']
2025-05-20 14:18:42,507 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'GSM8K_EN' for model 'gpt2'...
2025-05-20 14:18:42,508 - MathReasoningGenerationTaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:18:42,509 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'GSM8K_EN'. Intermediate log interval: 2
2025-05-20 14:18:48,055 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'GSM8K_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x0000020432ADFE90>> - Intermediate Metrics: {exact_match: 0.0000, rouge: {'rougeL_f': '0.2221'}}
2025-05-20 14:18:49,468 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'GSM8K_EN'. Processed 3 batches.
2025-05-20 14:18:49,468 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {}): 0.0
2025-05-20 14:18:49,501 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'rouge' (options: {'metrics': ['rougeL'], 'stats': ['f']}): {'rougeL_f': 0.24197209053435423}
2025-05-20 14:18:49,501 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'GSM8K_EN' on model 'gpt2': {exact_match: 0.0000, rouge: {rougeL_f: 0.2420}}
2025-05-20 14:18:49,501 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'GSM8K_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'rouge']
2025-05-20 14:18:49,501 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:272 - Running task 'MMLU_Anatomy_EN' for model 'gpt2'...
2025-05-20 14:18:49,501 - MultipleChoiceQATaskHandler_pytorch - MainThread - INFO - base_task_handler.__init__:43 - TaskHandler initialized for a 'pytorch' model.
2025-05-20 14:18:49,501 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:173 - Starting batch processing for task 'MMLU_Anatomy_EN'. Intermediate log interval: 2
2025-05-20 14:18:49,954 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:238 - Task 'MMLU_Anatomy_EN' - Batch 2/<bound method tqdm.__len__ of <tqdm.std.tqdm object at 0x000002043271FFE0>> - Intermediate Metrics: {exact_match: 0.6250, accuracy: 0.6250}
2025-05-20 14:18:50,012 - BenchmarkRunner - MainThread - INFO - benchmark_loader._process_task_batches:255 - Finished batch processing for task 'MMLU_Anatomy_EN'. Processed 3 batches.
2025-05-20 14:18:50,012 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'exact_match' (options: {'normalize': True, 'ignore_case': True}): 0.6
2025-05-20 14:18:50,012 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {}): 0.6
2025-05-20 14:18:50,012 - Evaluator - MainThread - WARNING - evaluator.finalize_results:133 - Metric name collision in final results: 'accuracy' (options: {'weighted': False}) is overwriting an existing entry with the same name.
2025-05-20 14:18:50,012 - Evaluator - MainThread - INFO - evaluator.finalize_results:139 - Finalized metric 'accuracy' (options: {'weighted': False}): 0.6
2025-05-20 14:18:50,012 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:358 - Final Evaluation Results for Task 'MMLU_Anatomy_EN' on model 'gpt2': {exact_match: 0.6000, accuracy: 0.6000}
2025-05-20 14:18:50,012 - BenchmarkRunner - MainThread - INFO - benchmark_loader._run_task_evaluation:363 - Task 'MMLU_Anatomy_EN' on model 'gpt2' evaluation completed. Metrics requested: ['exact_match', 'accuracy', 'accuracy']
2025-05-20 14:18:50,012 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:136 - Cleaning up resources for model 'gpt2'...
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader._cleanup_model_resources:142 - Resources cleaned up for model 'gpt2'.
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:444 - Saving intermediate results after processing model 'gpt2-custom-script-loader'...
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:18:50,159 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:18:50,159 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader.run:448 - All models processed. Saving final results...
2025-05-20 14:18:50,159 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:380 - Saving results to benchmarks_output_comprehensive_en in json format...
2025-05-20 14:18:50,162 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:166 - Saving results to benchmarks_output_comprehensive_en\benchmark_results.json...
2025-05-20 14:18:50,162 - benchmark.reporting.file_manager - MainThread - INFO - file_manager.save_results:168 - Results successfully saved to benchmarks_output_comprehensive_en\benchmark_results.json
2025-05-20 14:18:50,162 - BenchmarkRunner - MainThread - INFO - benchmark_loader._save_results:387 - Results saved successfully.
2025-05-20 14:18:50,165 - __main__ - MainThread - INFO - run_benchmark.main:102 - Benchmark completed successfully
